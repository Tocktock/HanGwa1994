{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from gensim import models\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np;np.random.seed(42)\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "xnum = 0\n",
    "ynum = 0\n",
    "with open('Tr.json', encoding=\"iso-8859-1\") as f:\n",
    "    json_data = json.load(f, encoding=\"utf-8\")\n",
    "    regex = re.compile(r'[가-힣]+/NNG')\n",
    "    noNNG = re.compile(r'[가-힣]+')\n",
    "    reAns = re.compile(r'[0-9]+')\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(json_data)):\n",
    "        TrainX = []\n",
    "        TrainY = []\n",
    "        for y in json_data[i]['answer']:\n",
    "            ynum = ynum + 1\n",
    "            y = reAns.findall(y)\n",
    "            TrainY = TrainY + y\n",
    "        #print(TrainY)\n",
    "        y_train.append(TrainY)\n",
    "        for j in json_data[i]['sentence']:\n",
    "            sentence = j.encode('iso-8859-1').decode('euc-kr', 'ignore')\n",
    "            matchWord = regex.findall(sentence)\n",
    "            sentence = ''.join(matchWord)\n",
    "            matchWord = noNNG.findall(sentence)\n",
    "            TrainX = TrainX + matchWord\n",
    "        x_train.append(TrainX)\n",
    "        xnum = xnum + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "for i in x_train:\n",
    "    x_data.append(' '.join(i))\n",
    "    \n",
    "y_data = []\n",
    "for a in y_train:\n",
    "    y_data.append(a[2:3])\n",
    "    \n",
    "y_data_string = []\n",
    "for c in y_data:\n",
    "    y_data_string.append(''.join(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF 구하기\n",
    "tfidf = TfidfVectorizer(max_features = 3000, lowercase=False)\n",
    "x_voca = tfidf.fit_transform(x_data)\n",
    "train_data = x_voca.toarray()\n",
    "\n",
    "#피쳐는 3천개로 0~2999의 값을 가짐.\n",
    "#행렬에서 가중치는 다를 것으로 예상함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(y_data_string)\n",
    "one_hot_lb = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 18006     \n",
      "=================================================================\n",
      "Total params: 18,006\n",
      "Trainable params: 18,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential();\n",
    "model.add(layers.Dense(6,input_shape=(train_data.shape[1], ),activation = 'relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JiYoung\\Anaconda2\\envs\\JiYoung\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2784 samples, validate on 696 samples\n",
      "Epoch 1/100\n",
      "2784/2784 [==============================] - 0s 98us/step - loss: 0.7781 - acc: 0.8333 - val_loss: 0.4854 - val_acc: 0.8333\n",
      "Epoch 2/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.4104 - acc: 0.8334 - val_loss: 0.3534 - val_acc: 0.8338\n",
      "Epoch 3/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.3074 - acc: 0.8408 - val_loss: 0.2896 - val_acc: 0.8527\n",
      "Epoch 4/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.2597 - acc: 0.8697 - val_loss: 0.2669 - val_acc: 0.8776\n",
      "Epoch 5/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.2311 - acc: 0.8921 - val_loss: 0.2493 - val_acc: 0.8954\n",
      "Epoch 6/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.2106 - acc: 0.9052 - val_loss: 0.2326 - val_acc: 0.9030\n",
      "Epoch 7/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1948 - acc: 0.9139 - val_loss: 0.2276 - val_acc: 0.9104\n",
      "Epoch 8/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.1824 - acc: 0.9210 - val_loss: 0.2248 - val_acc: 0.9167\n",
      "Epoch 9/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1723 - acc: 0.9262 - val_loss: 0.2186 - val_acc: 0.9198\n",
      "Epoch 10/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1640 - acc: 0.9309 - val_loss: 0.2271 - val_acc: 0.9210\n",
      "Epoch 11/100\n",
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.1571 - acc: 0.9338 - val_loss: 0.2183 - val_acc: 0.9219\n",
      "Epoch 12/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.1512 - acc: 0.9366 - val_loss: 0.2175 - val_acc: 0.9239\n",
      "Epoch 13/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1460 - acc: 0.9388 - val_loss: 0.2159 - val_acc: 0.9241\n",
      "Epoch 14/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1422 - acc: 0.9411 - val_loss: 0.2182 - val_acc: 0.9239\n",
      "Epoch 15/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1382 - acc: 0.9423 - val_loss: 0.2188 - val_acc: 0.9234\n",
      "Epoch 16/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1354 - acc: 0.9435 - val_loss: 0.2156 - val_acc: 0.9231\n",
      "Epoch 17/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.1334 - acc: 0.9445 - val_loss: 0.2134 - val_acc: 0.9231\n",
      "Epoch 18/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1302 - acc: 0.9453 - val_loss: 0.2150 - val_acc: 0.9231\n",
      "Epoch 19/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.1273 - acc: 0.9462 - val_loss: 0.2166 - val_acc: 0.9231\n",
      "Epoch 20/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.1247 - acc: 0.9460 - val_loss: 0.2177 - val_acc: 0.9222\n",
      "Epoch 21/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1223 - acc: 0.9459 - val_loss: 0.2148 - val_acc: 0.9219\n",
      "Epoch 22/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1199 - acc: 0.9467 - val_loss: 0.2187 - val_acc: 0.9219\n",
      "Epoch 23/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.1178 - acc: 0.9471 - val_loss: 0.2183 - val_acc: 0.9210\n",
      "Epoch 24/100\n",
      "2784/2784 [==============================] - 0s 38us/step - loss: 0.1158 - acc: 0.9480 - val_loss: 0.2174 - val_acc: 0.9217\n",
      "Epoch 25/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1139 - acc: 0.9479 - val_loss: 0.2172 - val_acc: 0.9217\n",
      "Epoch 26/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.1121 - acc: 0.9480 - val_loss: 0.2200 - val_acc: 0.9215\n",
      "Epoch 27/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1104 - acc: 0.9482 - val_loss: 0.2225 - val_acc: 0.9210\n",
      "Epoch 28/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.1088 - acc: 0.9482 - val_loss: 0.2223 - val_acc: 0.9200\n",
      "Epoch 29/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.1072 - acc: 0.9484 - val_loss: 0.2271 - val_acc: 0.9198\n",
      "Epoch 30/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.1058 - acc: 0.9486 - val_loss: 0.2270 - val_acc: 0.9210\n",
      "Epoch 31/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.1043 - acc: 0.9491 - val_loss: 0.2246 - val_acc: 0.9205\n",
      "Epoch 32/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.1030 - acc: 0.9492 - val_loss: 0.2298 - val_acc: 0.9203\n",
      "Epoch 33/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.1016 - acc: 0.9491 - val_loss: 0.2322 - val_acc: 0.9203\n",
      "Epoch 34/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.1003 - acc: 0.9496 - val_loss: 0.2320 - val_acc: 0.9195\n",
      "Epoch 35/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0992 - acc: 0.9497 - val_loss: 0.2324 - val_acc: 0.9186\n",
      "Epoch 36/100\n",
      "2784/2784 [==============================] - 0s 46us/step - loss: 0.0980 - acc: 0.9501 - val_loss: 0.2354 - val_acc: 0.9188\n",
      "Epoch 37/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0970 - acc: 0.9500 - val_loss: 0.2347 - val_acc: 0.9183\n",
      "Epoch 38/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0959 - acc: 0.9500 - val_loss: 0.2374 - val_acc: 0.9181\n",
      "Epoch 39/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0949 - acc: 0.9495 - val_loss: 0.2381 - val_acc: 0.9179\n",
      "Epoch 40/100\n",
      "2784/2784 [==============================] - 0s 46us/step - loss: 0.0926 - acc: 0.9497 - val_loss: 0.2388 - val_acc: 0.9176\n",
      "Epoch 41/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0914 - acc: 0.9494 - val_loss: 0.2383 - val_acc: 0.9176\n",
      "Epoch 42/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0905 - acc: 0.9494 - val_loss: 0.2438 - val_acc: 0.9174\n",
      "Epoch 43/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0896 - acc: 0.9495 - val_loss: 0.2491 - val_acc: 0.9169\n",
      "Epoch 44/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0880 - acc: 0.9491 - val_loss: 0.2471 - val_acc: 0.9167\n",
      "Epoch 45/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0871 - acc: 0.9494 - val_loss: 0.2494 - val_acc: 0.9169\n",
      "Epoch 46/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.0862 - acc: 0.9491 - val_loss: 0.2521 - val_acc: 0.9162\n",
      "Epoch 47/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0854 - acc: 0.9486 - val_loss: 0.2507 - val_acc: 0.9159\n",
      "Epoch 48/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0845 - acc: 0.9489 - val_loss: 0.2549 - val_acc: 0.9159\n",
      "Epoch 49/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0838 - acc: 0.9486 - val_loss: 0.2554 - val_acc: 0.9159\n",
      "Epoch 50/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0830 - acc: 0.9484 - val_loss: 0.2582 - val_acc: 0.9150\n",
      "Epoch 51/100\n",
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.0823 - acc: 0.9483 - val_loss: 0.2539 - val_acc: 0.9148\n",
      "Epoch 52/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0817 - acc: 0.9484 - val_loss: 0.2584 - val_acc: 0.9143\n",
      "Epoch 53/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0809 - acc: 0.9479 - val_loss: 0.2581 - val_acc: 0.9138\n",
      "Epoch 54/100\n",
      "2784/2784 [==============================] - 0s 46us/step - loss: 0.0803 - acc: 0.9480 - val_loss: 0.2583 - val_acc: 0.9131\n",
      "Epoch 55/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0796 - acc: 0.9476 - val_loss: 0.2582 - val_acc: 0.9119\n",
      "Epoch 56/100\n",
      "2784/2784 [==============================] - 0s 38us/step - loss: 0.0789 - acc: 0.9479 - val_loss: 0.2590 - val_acc: 0.9119\n",
      "Epoch 57/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0783 - acc: 0.9484 - val_loss: 0.2593 - val_acc: 0.9121\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.0777 - acc: 0.9486 - val_loss: 0.2621 - val_acc: 0.9119\n",
      "Epoch 59/100\n",
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.0772 - acc: 0.9484 - val_loss: 0.2621 - val_acc: 0.9124\n",
      "Epoch 60/100\n",
      "2784/2784 [==============================] - 0s 46us/step - loss: 0.0765 - acc: 0.9487 - val_loss: 0.2610 - val_acc: 0.9124\n",
      "Epoch 61/100\n",
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.0761 - acc: 0.9492 - val_loss: 0.2649 - val_acc: 0.9114\n",
      "Epoch 62/100\n",
      "2784/2784 [==============================] - 0s 51us/step - loss: 0.0755 - acc: 0.9486 - val_loss: 0.2677 - val_acc: 0.9109\n",
      "Epoch 63/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0750 - acc: 0.9492 - val_loss: 0.2677 - val_acc: 0.9112\n",
      "Epoch 64/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0744 - acc: 0.9488 - val_loss: 0.2680 - val_acc: 0.9114\n",
      "Epoch 65/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0740 - acc: 0.9488 - val_loss: 0.2683 - val_acc: 0.9116\n",
      "Epoch 66/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0734 - acc: 0.9492 - val_loss: 0.2710 - val_acc: 0.9109\n",
      "Epoch 67/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0729 - acc: 0.9492 - val_loss: 0.2680 - val_acc: 0.9102\n",
      "Epoch 68/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0725 - acc: 0.9492 - val_loss: 0.2684 - val_acc: 0.9109\n",
      "Epoch 69/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0721 - acc: 0.9493 - val_loss: 0.2712 - val_acc: 0.9104\n",
      "Epoch 70/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0716 - acc: 0.9493 - val_loss: 0.2690 - val_acc: 0.9109\n",
      "Epoch 71/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0711 - acc: 0.9492 - val_loss: 0.2693 - val_acc: 0.9107\n",
      "Epoch 72/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0706 - acc: 0.9491 - val_loss: 0.2727 - val_acc: 0.9109\n",
      "Epoch 73/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.0702 - acc: 0.9491 - val_loss: 0.2734 - val_acc: 0.9104\n",
      "Epoch 74/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0698 - acc: 0.9492 - val_loss: 0.2749 - val_acc: 0.9104\n",
      "Epoch 75/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0693 - acc: 0.9489 - val_loss: 0.2754 - val_acc: 0.9100\n",
      "Epoch 76/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0689 - acc: 0.9489 - val_loss: 0.2754 - val_acc: 0.9090\n",
      "Epoch 77/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0685 - acc: 0.9489 - val_loss: 0.2792 - val_acc: 0.9080\n",
      "Epoch 78/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0681 - acc: 0.9491 - val_loss: 0.2788 - val_acc: 0.9080\n",
      "Epoch 79/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.0677 - acc: 0.9485 - val_loss: 0.2817 - val_acc: 0.9083\n",
      "Epoch 80/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0673 - acc: 0.9488 - val_loss: 0.2810 - val_acc: 0.9088\n",
      "Epoch 81/100\n",
      "2784/2784 [==============================] - 0s 46us/step - loss: 0.0669 - acc: 0.9492 - val_loss: 0.2817 - val_acc: 0.9078\n",
      "Epoch 82/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0666 - acc: 0.9485 - val_loss: 0.2836 - val_acc: 0.9078\n",
      "Epoch 83/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0661 - acc: 0.9490 - val_loss: 0.2881 - val_acc: 0.9076\n",
      "Epoch 84/100\n",
      "2784/2784 [==============================] - 0s 45us/step - loss: 0.0658 - acc: 0.9489 - val_loss: 0.2838 - val_acc: 0.9073\n",
      "Epoch 85/100\n",
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.0654 - acc: 0.9485 - val_loss: 0.2914 - val_acc: 0.9076\n",
      "Epoch 86/100\n",
      "2784/2784 [==============================] - 0s 44us/step - loss: 0.0651 - acc: 0.9486 - val_loss: 0.2889 - val_acc: 0.9071\n",
      "Epoch 87/100\n",
      "2784/2784 [==============================] - 0s 39us/step - loss: 0.0648 - acc: 0.9483 - val_loss: 0.2889 - val_acc: 0.9068\n",
      "Epoch 88/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0645 - acc: 0.9488 - val_loss: 0.2899 - val_acc: 0.9066\n",
      "Epoch 89/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0641 - acc: 0.9488 - val_loss: 0.2902 - val_acc: 0.9059\n",
      "Epoch 90/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0638 - acc: 0.9488 - val_loss: 0.2953 - val_acc: 0.9071\n",
      "Epoch 91/100\n",
      "2784/2784 [==============================] - 0s 46us/step - loss: 0.0635 - acc: 0.9488 - val_loss: 0.2931 - val_acc: 0.9071\n",
      "Epoch 92/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0631 - acc: 0.9483 - val_loss: 0.2957 - val_acc: 0.9073\n",
      "Epoch 93/100\n",
      "2784/2784 [==============================] - 0s 42us/step - loss: 0.0628 - acc: 0.9480 - val_loss: 0.2938 - val_acc: 0.9066\n",
      "Epoch 94/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0625 - acc: 0.9480 - val_loss: 0.2947 - val_acc: 0.9061\n",
      "Epoch 95/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0622 - acc: 0.9479 - val_loss: 0.2972 - val_acc: 0.9068\n",
      "Epoch 96/100\n",
      "2784/2784 [==============================] - 0s 41us/step - loss: 0.0618 - acc: 0.9476 - val_loss: 0.2974 - val_acc: 0.9066\n",
      "Epoch 97/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0616 - acc: 0.9477 - val_loss: 0.3007 - val_acc: 0.9059\n",
      "Epoch 98/100\n",
      "2784/2784 [==============================] - 0s 40us/step - loss: 0.0613 - acc: 0.9478 - val_loss: 0.3010 - val_acc: 0.9054\n",
      "Epoch 99/100\n",
      "2784/2784 [==============================] - 0s 43us/step - loss: 0.0610 - acc: 0.9476 - val_loss: 0.3013 - val_acc: 0.9061\n",
      "Epoch 100/100\n",
      "2784/2784 [==============================] - 0s 47us/step - loss: 0.0607 - acc: 0.9476 - val_loss: 0.3043 - val_acc: 0.9057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a96751e550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5겹 교차 검증 하겠음\n",
    "k_fold = 5\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(train_data,one_hot_lb,epochs=100, batch_size=32,validation_split=0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#테스트 데이터 받아오기.\n",
    "x_test = []\n",
    "y_test = []\n",
    "with open('Te.json', encoding=\"iso-8859-1\") as f:\n",
    "    json_data = json.load(f, encoding=\"utf-8\")\n",
    "    regex = re.compile(r'[가-힣]+/NNG')\n",
    "    noNNG = re.compile(r'[가-힣]+')\n",
    "    reAns = re.compile(r'[0-9]+')\n",
    "    for i in range(len(json_data)):\n",
    "        testX = []\n",
    "        textY = []\n",
    "        for y in json_data[i]['answer']:\n",
    "            y = reAns.findall(y)\n",
    "            textY = textY + y\n",
    "        y_test.append(textY)\n",
    "        for j in json_data[i]['sentence']:\n",
    "            sentence = j.encode('iso-8859-1').decode('euc-kr', 'ignore')\n",
    "            matchWord = regex.findall(sentence)\n",
    "            sentence = ''.join(matchWord)\n",
    "            matchWord = noNNG.findall(sentence)\n",
    "            testX = testX + matchWord\n",
    "        x_test.append(testX)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497\n",
      "1497\n",
      "(1497, 6)\n"
     ]
    }
   ],
   "source": [
    "x_data_test = []\n",
    "for i in x_test:\n",
    "    x_data_test.append(' '.join(i))\n",
    "    \n",
    "y_data_test = []\n",
    "for a in y_test:\n",
    "    y_data_test.append(a[2:3])\n",
    "print\n",
    "    \n",
    "y_data_test_string = []\n",
    "for c in y_data_test:\n",
    "    y_data_test_string.append(''.join(c))\n",
    "print(len(y_data_test_string))\n",
    "print(len(x_test))\n",
    "    \n",
    "y_lb = lb.fit_transform(y_data_test_string)ㅇ\n",
    "one_hot_lb_test = to_categorical(y_lb)\n",
    "print(one_hot_lb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_test = tfidf.transform(x_data_test)\n",
    "x_data_test = x_data_test.toarray()\n",
    "y_pred = model.predict(x_data_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1497 [==============================] - 0s 20us/step\n",
      "0.9028056047722428\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_data_test, one_hot_lb_test, batch_size=32)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
